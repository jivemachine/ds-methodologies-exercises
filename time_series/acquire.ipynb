{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "All of the exercises for this module should be done within your ds-methodologies repository, inside of a directory named time_series.\n",
    "\n",
    "The end result of this exercise should be a file named acquire.py.\n",
    "\n",
    "    1. Using the code from the lesson as a guide, create a dataframe named items that has all of the data for items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_df, get_store_data, german_energy_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://python.zach.lol'\n",
    "print(requests.get(url).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url + '/documentation')\n",
    "print(response.json()['payload'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://python.zach.lol/api/v1/items')\n",
    "\n",
    "data = response.json()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['payload'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.DataFrame(data['payload']['items'])\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = get_df('items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_brand</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_upc12</th>\n",
       "      <th>item_upc14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Riceland</td>\n",
       "      <td>1</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caress</td>\n",
       "      <td>2</td>\n",
       "      <td>Caress Velvet Bliss Ultra Silkening Beauty Bar...</td>\n",
       "      <td>6.44</td>\n",
       "      <td>11111065925</td>\n",
       "      <td>11111065925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Earths Best</td>\n",
       "      <td>3</td>\n",
       "      <td>Earths Best Organic Fruit Yogurt Smoothie Mixe...</td>\n",
       "      <td>2.43</td>\n",
       "      <td>23923330139</td>\n",
       "      <td>23923330139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boars Head</td>\n",
       "      <td>4</td>\n",
       "      <td>Boars Head Sliced White American Cheese - 120 Ct</td>\n",
       "      <td>3.14</td>\n",
       "      <td>208528800007</td>\n",
       "      <td>208528800007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Back To Nature</td>\n",
       "      <td>5</td>\n",
       "      <td>Back To Nature Gluten Free White Cheddar Rice ...</td>\n",
       "      <td>2.61</td>\n",
       "      <td>759283100036</td>\n",
       "      <td>759283100036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_brand  item_id                                          item_name  \\\n",
       "0        Riceland        1                     Riceland American Jazmine Rice   \n",
       "1          Caress        2  Caress Velvet Bliss Ultra Silkening Beauty Bar...   \n",
       "2     Earths Best        3  Earths Best Organic Fruit Yogurt Smoothie Mixe...   \n",
       "3      Boars Head        4   Boars Head Sliced White American Cheese - 120 Ct   \n",
       "4  Back To Nature        5  Back To Nature Gluten Free White Cheddar Rice ...   \n",
       "\n",
       "   item_price    item_upc12    item_upc14  \n",
       "0        0.84   35200264013   35200264013  \n",
       "1        6.44   11111065925   11111065925  \n",
       "2        2.43   23923330139   23923330139  \n",
       "3        3.14  208528800007  208528800007  \n",
       "4        2.61  759283100036  759283100036  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Do the same thing, but for stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://python.zach.lol/api/v1/stores')\n",
    "\n",
    "data = response.json()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['payload'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = pd.DataFrame(data['payload']['stores'])\n",
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = get_df('stores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Extract the data for sales. There are a lot of pages of data here, so your code will need to be a little more complex. Your code should continue fetching data from the next page until all of the data is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://python.zach.lol/api/v1/sales')\n",
    "\n",
    "data = response.json()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['payload'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['payload']['max_page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.DataFrame(data['payload']['sales'])\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entries = []\n",
    "\n",
    "base_url = 'https://python.zach.lol/api/v1/sales'\n",
    "response = requests.get(base_url, auth=(\"APIKEY\", ''))\n",
    "data = response.json()\n",
    "#total_pages = data['payload']['max_page']\n",
    "#next_page = data['payload']['next_page']\n",
    "for i in data:\n",
    "    all_entries.append(i)\n",
    "\n",
    "while response.links['next'] != response.links['last']:\n",
    "    r = requests.get(r.links['next'], auth=('APIKEY', '')\n",
    "    data = r.json()\n",
    "    for i in data:\n",
    "        all_entries.append(i)\n",
    "    \n",
    "\n",
    "\n",
    "#sales = pd.concat([sales, pd.DataFrame(data['payload']['sales'])]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_entries():\n",
    "    base_url = 'https://python.zach.lol/api/v1/sales'\n",
    "    response = requests.get(base_url)\n",
    "    data = response.json()\n",
    "    total_pages = data['payload']['max_page']\n",
    "    all_entries = []\n",
    "    for page in range(1, total_pages):\n",
    "        first = data['payload']['sales']\n",
    "        url = data['payload']['next_page']\n",
    "        r = requests.get('https://python.zach.lol' + url)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_all_data(url_address):  \n",
    "    # find out total number of pages\n",
    "    r = requests.get(url=url_address)\n",
    "    data = r.json()\n",
    "    total_pages = data['payload']['max_page']\n",
    "\n",
    "    # loop through all pages and return JSON object\n",
    "    for page in range(1, total_pages):\n",
    "        print(\"Acquiring data {} of {}\".format(data['payload']['page'] + 1, data['payload']['max_page']))\n",
    "        url = \"https://python.zach.lol/api/v1/sales?page=\" + data['payload']['next_page']              \n",
    "        response = requests.get(url=url)\n",
    "        data = response.json()\n",
    "        all_entries.append(response)       \n",
    "        page += 1\n",
    "    \n",
    "    # convert list file into pandas df\n",
    "\n",
    "    sales = pd.DataFrame(all_entries)\n",
    "    return sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://python.zach.lol/api/v1/sales\"\n",
    "sales = get_all_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales_data():\n",
    "    # uses base url near imports\n",
    "    ext = '/sales'\n",
    "    response = requests.get(base_url + ext)\n",
    "    \n",
    "    # creates json object\n",
    "    data = response.json()\n",
    "    # get first page\n",
    "    sales_data = data['payload']['sales']\n",
    "    total_pages = data['payload']['max_page']\n",
    "    \n",
    "    while data['payload']['next_page'] <= total_pages:\n",
    "        url = base_url + data['payload']['next_page']\n",
    "        r = requests.get(base_url + ext)\n",
    "        data = r.json()\n",
    "        sales_data += data['payload']['sales']\n",
    "        \n",
    "    df = pd.DataFrame(sales_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_sales_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://python.zach.lol'\n",
    "API_BASE = BASE_URL + '/api/v1'\n",
    "\n",
    "def get_sale_data_from_api():\n",
    "    url = API_BASE + '/sales'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    stores = data['payload']['sales']\n",
    "\n",
    "    while data['payload']['next_page'] is not None:\n",
    "        print('Fetching page {} of {}'.format(data['payload']['page'] + 1, data['payload']['max_page']))\n",
    "        url = BASE_URL + data['payload']['next_page']\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        stores += data['payload']['sales']\n",
    "\n",
    "    df = pd.DataFrame(stores)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_sale_data_from_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.DataFrame(all_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pages = data['payload']['max_page']\n",
    "total_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_pages():\n",
    "    \n",
    "    base_url = 'https://python.zach.lol/api/v1/sales'\n",
    "    data = response.json()\n",
    "    response = requests.get(base_url + data['payload']['next_page'])\n",
    "    #total_pages = data['payload']['max_page']\n",
    "    #entries = pd.DataFrame()\n",
    "        \n",
    "    #for page in range(1, total_pages):\n",
    "    #    url = 'https://python.zach.lol/api/v1/sales?page='+str(page)\n",
    "    #    response = requests.get(url=url).json()\n",
    "    #    entries.append(response)\n",
    "    #    page += 1\n",
    "    #return data\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = get_df('sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. Save the data in your files to local csv files so that it will be faster to access in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5. Combine the data from your three separate dataframes into one large dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    6. Acquire the Open Power Systems Data for Germany, which has been rapidly expanding its renewable energy production in recent years. The data set includes country-wide totals of electricity consumption, wind power production, and solar power production for 2006-2017. You can get the data here: https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    7. Make sure all the work that you have done above is reproducible. That is, you should put the code above into separate functions in the acquire.py file and be able to re-run the functions and get the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
